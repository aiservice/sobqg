<!DOCTYPE html> <html lang="zh"> <head> <meta charset="UTF-8">
    <title>第249章 弱小</title>
</head>
<body class="calibreEbookContent">
<p>易科的“太白”出世，以一种迅雷不及掩耳的速度击穿人类围棋阵营，但即便是1V5，即便是人类顶尖棋手，不少人对于易科堂而皇之的宣称AI已经在围棋领域超越人类智慧还是不满。</p><p>这里面还有许多言之有理的理由，比如，AI出现的太突然，所有人都来不及仔细研究它的下棋路数；比如，时间太近，棋手们没有完全调整到最佳状态……</p><p>只是，眼下已经来不及为人类棋手遗憾了，现在赶到战场的是来自谷歌的“阿尔法”。</p><p>继AI无可匹敌的战胜人类，易科快速确定与谷歌的技术切磋时间，直接定在了7月3日，仍旧是全程开启直播。</p><p>方卓不懂围棋，但他对于这种技术的验证和交流很有兴趣。</p><p>这次不仅仅是两个AI的对弈，易科也是在上海举办了一次与谷歌的深度学习Deep Learning的交流活动，同时还有英伟达以及硅谷近期这领域的研发人员、创业公司一起参加。</p><p>易科是真的抱着切磋的意愿，谷歌与硅谷那边也没有太多比试高低的意思，因为，这个赛道的折腾确实还没瞧见太多突破的希望，仍旧属于蓄力阶段。</p><p>也正是基于这种情况，不少没被邀请的研发者和公司瞧见两大公司的互动，也积极报名参加活动，而易科在与谷歌讨论之后就干脆扩大了规模，时间也顺势推迟到7月10日。</p><p>这便不是一场围棋对弈的AI互动，而是以它当做开胃菜的深度学习DL的研讨会议。</p><p>7月10日，易科、谷歌、英伟达等公司在上海的易科中心举办会议，同时，易科还邀请了先前被击败的柯洁、李世石、申真谞等人作为嘉宾，见证“太白”与“阿尔法”的对决。</p><p>这两个AI都有击败人类顶尖棋手的履历，太白上个月掀起的多面打与舆论炒作也成功让大众对AI充满兴趣，再加上又有现场直播，所以，观看者众多。</p><p>上午九点钟，两台机器人坐在舞台的正中央，现场架设了大屏幕，方卓、拉里等人坐在第一排，棋手柯洁、申真谞等嘉宾在直播室点评。</p><p>不同于上次同样直播的1V5，“太白”与“阿尔法”的落子都十分迅速，偶尔也有迟疑的时候，但这种时刻相较于人类便显得极其短暂。</p><p>对弈是传统规则，各自是有三小时时间，然而，仅仅三十二分钟，这场万众瞩目的棋就以“太白”赢下1子而结束。</p><p>这三十二分钟是绝大多数人看不懂的三十二分钟，不过，他们能看到棋手们的表现，能看到直播室里刚开始有分歧，中间有争执，最终变成沉默的过程。</p><p>当柯洁被邀请上台，以专业人士的身份对这盘棋进行点评，他面对镜头十分茫然，好一会之后才说道：“AI在围棋上可能已经完全超出人类想象了，上个月我好像在AI的棋里看到了古力、李昌镐、吴清源他们的影子，又、又好像看到了我自己的影子。”</p><p>柯洁神色中带着挣扎和痛苦，伸手捂脸：“今天，我看不到了，完全看不到了，我好像不懂，不懂围棋到底该是什么样了……”</p><p>主持人眼看柯洁已经有些失态，赶紧把这位人类顶尖棋手请下台，并且打了打圆场，但这个场面无疑让观看直播的人印象深刻。</p><p>AI对弈的开胃菜结束，方卓拿到话筒进行了简单的发言。</p><p>“围棋是人类智慧的杰作，但AI也是如此。”</p><p>“我对于AI的期待就是它能够极大的解放人类的双手，这一天大概很远，但就像今天的‘太白’相较于上个月的它，已经又有进步。”</p><p>“AI会以一种让人惊叹的迭代速度进化，我们今天汇聚在这里也是为了寻找正确的发展方向。”</p><p>“AI是在围棋领域赢了人类，但这不是人类智慧的终结，反而是人类智慧的延伸，是科技的又一次进步，也是对未来的又一次探索。”</p><p>方卓这种看法的表达还是赢来了不少掌声与直播间的好评。</p><p>对于许多人来说，这场热闹也就看到这里了，但对从业者、研发人员来说，真正的部分才刚刚开始，不论易科还是谷歌都在深度学习DL领域有很深的研究，这种围棋对弈只是展露出的表象，内里的运转与思考才是更让人重视的。</p><p>吴恩达作为易科“Venus”项目的负责人之一，与谷歌旗下公司的席尔瓦就DL的模型逻辑进行了交流。</p><p>不管太白还是阿尔法，它们都是基于卷积神经网络的发展而来，这一基础是类似的，而它的突破源于2012年Alex、Ilya和Hinton合作发表的关于AlexNet深度卷积神经网络的论文，也正是在这之后，相关的研究出现了爆炸式的增长。</p><p>吴恩达与席尔瓦谈的是在AlexNet之后的架构创新，是将传统的搜索算法与深度学习模型的有效整合，以及，整个团队在局部感受野、参数共享与稀疏连接、平移不变性这些方面做出的努力。</p><p>这种易科与谷歌以及场下嘉宾的交流极其愉快，也让方卓颇为满意，他虽然不懂，但瞧着这样的场面就觉得知识被塞进了脑子里。</p><p>只是，等到第二天，当吴恩达提出团队在研发上的困惑时，激烈的辩论到来了。</p><p>易科是有“Siri”这样的语音助手作为人工智能的实践，而吴恩达的团队不仅在做卷积神经网络CNN的研究，也在做循环神经网络RNN的研究，他们认为后者更适合与语音助手相结合，但效果并不算很好，完全达不到想要的成绩。</p><p>问题出在哪里？</p><p>吴恩达表述了困惑，也谈了谈易科内部的解决方向。</p><p>参会的一部分人赞同易科的解题思路，但谷歌方面却出现了不同的声音。</p><p>“为什么非要使用循环神经网络？”谷歌的乌思克尔特本来正在休假，但因为对DL的交流感兴趣便报名过来，“为什么不试试自注意力Self-attention？我认为它对NLP领域将会有更优秀的改变。”</p><p>“Self-attention可以进行更好的并行计算能力，而不是像RNN那样进行顺序处理，它还能直接比较序列中任意两个位置的向量表示，这样就能更有效的捕捉和利用长距离依赖关系，但RNN不行！”</p><p>“RNN虽然理论上也能捕捉长距离依赖，但实际上往往因梯度消失或爆炸问题而难以实现！”</p><p>乌思克尔特研究的是谷歌的机器翻译改进方法，他的父亲就是计算语言学的教授，尽管刚开始进入谷歌时对语言翻译的工作很不喜欢，但最终还是专注于这一领域的研究，而他近期正在琢磨的便是“自注意力Self-attention”在相关领域的改善。</p><p>吴恩达很快明白这位谷歌研究员的意思，也在几经思索后给予反驳：“自注意力没有显式地编码位置信息，这就意味着如果以它为核心的模型无法区分序列中相同词语在不同位置的意义差异，而在自然语言的处理中，词语的语义又与位置紧密相关。”</p><p>“而且，自注意力模型必然因为序列中每对元素计算的注意力权重而有巨大的参数量，这极可能导致过拟合。”</p><p>他这边刚说话，谷歌自家DL的席尔瓦也反驳了乌思克尔特提出的新路线，其中一个重要原因在于RNN的循环结构太符合大家对序列数据处理的理解，即当前状态依赖于过去的信息，而自注意力的全局依赖一看就不如RNN直观。</p><p>易科与谷歌的两大领导者都批评了自注意力Self-attention，但乌思克尔特并不服气，他直接登台阐述自己更多的想法。</p><p>而且，针对吴恩达与席尔瓦抨击的缺点也给出一些解决思路，比如，引入位置编码，比如，进行多头注意力的研究。</p><p>有人觉得眼前一亮，有人觉得异想天开，还有人现场进行快速的分析和演算。</p><p>第一排的方卓极其茫然，他扭头询问旁边沉思的英伟达掌门人黄仁勋：“他们在讨论什么？”</p><p>“乌思克尔特说，GPU是最适合深度学习技术的硬件。”黄仁勋给出一句总结。</p><p>方卓：“？？？”</p><p>他纳闷道：“我怎么完全没听到类似的表述？”</p><p>“因为自注意力Self-Attention更加强调并行处理，这是GPU更擅长的。”黄仁勋笑道，“至于其他的，不重要，我们只要提取对我们有利的就好。”</p><p>方卓观察着现场的气氛，这已经不是知识的交流，更像是知识的火拼了。</p><p>他默默的收起自己在这种场合本就不多的存在感。</p><p>只是，等到晚上，方卓还是当面询问了这次参与辩论的吴恩达，想知道这场面红耳赤的讨论都有些什么东西。</p><p>吴恩达真的很难和方总解释发生了什么。</p><p>“方总，等我们想一想再写一份报告吧。”他思考许久之后由衷地说道，“这样的交流或许应该多来几次，他那个自注意力，我现在想想，缺点也不是不能解决。”</p><p>方卓耐心的询问：“那我们应该做些什么？”</p><p>吴恩达回味今天的整场辩论，思考着不同人提出的不同想法，喃喃道：“或许，我们需要先试试一种新型软件，让它可以和计算机对话。”</p><p>方卓“嗯”了一声，表达一贯的支持：“行，开始吧。”</p><p>吴恩达哭笑不得，真心地说道：“方总，你给我们的支持真的太优渥了。”</p><p>“我也就只能给我所能给的东西。”方卓笑道，“试试呗，如果人手不够，那就国内再招招人，我是朴素的认知哈，既然能引起争论，新的东西就有可取之处。”</p><p>吴恩达竖起拇指，喜欢老板的这种支持。</p><p>只是，易科的现状并不是那么美妙。</p><p>他提出了这方面的小小担忧。</p><p>方卓不以为意地说道：“你们这些投入才多少钱，正好英伟达的一批GPU快到货了，先用看吧，我看黄仁勋今天笑得特别开心。”</p><p>吴恩达要不是不擅长搞商业的事情，恨不得赤膊上阵帮易科卖货了。</p><p>不过，他虽然不能卖货，但易科与谷歌还有硅谷公司们的交流热度直接进一步稳住了公司的股价。</p><p>易科看起来是有扎实的研发的，尽管不知何时能有商业价值，但AI在围棋领域击败人类无疑是一次实打实的突破。</p><p>易科股价已经跌得足够惨了，难道现在还不够吗？</p><p>针对媒体里出现的这种声音，RC对冲基金的拉塞尔颇有些气急败坏，他和一帮空头同样在关注易科近期与谷歌等公司的交流，但是，并不认可这个领域对易科股价的提升。</p><p>不仅如此，拉塞尔还请来了美国厂商杜邦公司的高层康博恩，让专业人士对易科与冰芯的现状进行判断。</p><p>“冰芯的光刻胶肯定已经用完了！这是材料本身决定的，冰芯不可能违背现实定律！”</p><p>“中国的光刻胶很落后，最少五年之内都不可能为冰芯提供可用的原材料！”</p><p>来自杜邦的高层在镜头面前信誓旦旦的给予结论。</p><p>这种垄断领域的专业论断确实让一些人对易科、冰芯的未来产生阴影，而时间进入七月，易科手机的市场表现似乎也验证了冰芯尖端工艺停产的可能性。</p><p>不过，拉塞尔私底下与康博恩的交流在时限上有小小的缩水。</p><p>“短则两年，长则三年，冰芯就有能用的光刻胶。”康博恩仍旧对于自己的判断信誓旦旦，“不能太高估易科与冰芯这方面的研发，但也不能太低估。”</p><p>他在电视上夸大了一倍的预期，那是真心夸大，但现在也是真心帮拉塞尔分析情况。</p><p>“两三年的时间，足够了，完全足够了。”拉塞尔很满意这样的动作给易科的股价带来的刺激，“这已经足够让易科产生难以挽回的衰退了。”</p><p>他评价了易科：“康博恩，易科有一个缺点，你知道是什么吗？”</p><p>康博恩聆听这位空头的高见：“是什么？”</p><p>拉塞尔笑道：“易科只有一个缺点，它不够强。”</p><p>康博恩持保留意见，世界上就不会有面面俱到的公司，易科已经很强了，但他也尊重这位正在狙击易科股票的空头。</p><p>并且，他还在推特上分享了与这位的交流。</p><p>——易科只有一个缺点，它不够强。</p><p>7月19日，不够强的易科发布了Q2财报，向市场陈述当前阶段的公司财务状况与这段时间的转变。</p><p>整个二季度，易科的营收环比Q1再度下降，从293.44亿美元降到181.4亿美元，幅度达到38.18%，而运营利润、净利润等关键数据也有较为一致的下滑。</p><p>通常来说，二季度属于淡季，易科往年的二季度也都会比一季度的数字要低，但抛开常规影响，这个38.18%的下滑仍旧十分难看。</p><p>尽管，华尔街对于易科Q2的财报出现了不同声音，认为“广告营收大幅升高”“技术许可费用大幅升高”“云业务的增长出乎意料”这些共同支撑住易科的转型，但是，近期稳在2800亿美元的易科市值还是骤然下跌。</p><p>截止到7月26日，易科市值在一周之内跌至2513亿美元。</p><p>易科在中国有YA的两极之称，而随着它这样的跌幅，已经距离阿里如今2289亿美元的市值很近了，两者就差一个半的百度。</p><p>RC对冲基金的拉塞尔第一时间嘲笑了易科的下滑。</p><p>“哈哈哈，方总干了这些年，公司市值也就干出个阿里巴巴！”</p><p>“概念只是一时的，AI没有取得实质突破，它的热度很快就会过去，易科正在回到它应该在的位置上！”</p><p>“我早就说过，易科已经没有魔力了，方总已经没有魔力了！”</p><p>“他搞砸了一切！易科已经被他搞砸了！”</p>

</body>
</html>